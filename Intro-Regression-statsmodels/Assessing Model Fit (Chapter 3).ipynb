{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of Determination\n",
    "How strong is the linear relationship?\n",
    "\n",
    "one metric is **r-squared** (coefficienc of determination)(lowercase are for simple linear regression and uppercase R when you have more than one explanatory variable\n",
    "\n",
    "the proportion of the variance in the response variable that is predictable from the explanatory variable\n",
    "\n",
    "a score of 1 means the model is a perfect fit and a score of 0 is no better than randomness, the score means that the number of impressions explains 89% of the variability in the number of clicks\n",
    "\n",
    "shows up in the first line of .summary(), an easier way to extract the metric is to use to use the .rsquared attribute\n",
    "\n",
    "for simple linear regression, the CoD is the correlation between the explanatory and response variables squared\n",
    "\n",
    "another metric is the **residual standard error (RSE)**, each residual is the difference between a predicted value and an observed value, the RSE is kinda like the measure of the typical size of the residuals (how much the predictions are typically wrong), has the same unit as the response variable, **mean squared error (MSE)** is related by less commonly used, it's the squared RSE, .mse_resid can be square rooted to get the RSE\n",
    "- mse = mdl_koi.mse_resid\n",
    "- rse = np.sqrt(mse)\n",
    "an RSE of 74 would mean that the difference between the predicted bream masses and the observed bream masses is typically about 74 grams\n",
    "\n",
    "another metric which is related is the **root-mean-square error (RMSE)**, this is calculated the same way except the number of coefficents isn't subtracted, it's just like RSE (quantifies how inaccurate the model predictions are) but is worse for comparisons between models, you should mostly use RSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Model Fit\n",
    "if the linear regression model is a good fit then the residuals are approximately normally distributed and the mean of the residuals will be 0\n",
    "there's a few diagnostic plots that can help you visualize this\n",
    "\n",
    "**residuals versus fitted values**\n",
    "the blue line is a Lowess trend line, it's a smooth curve following the data, it's not good for making predictions but is useful for visualizing trends, a good fit would mean that the trend line would closely follow the y=0 line of the plot\n",
    "    sns.residplot(x=\"length_cm\", y=\"mass_g\", data=koi, lowess=True)\n",
    "    plt.xlabel(\"Fitted Values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "\n",
    "**Q-Q plot**\n",
    "shows whether or not the residuals follow a normal distribution, the x-axis is quantiles from the normal distribution, the y-axis is the sample quantiles (quantiles derived from your dataset), if the points track along the straight line they are normally distributed, the highest residuals are the points on the ends\n",
    "    from statsmodels.api import qqplot\n",
    "    qqplot(data=mdl_koi.resid, fit=True, line=\"45\")\n",
    "\n",
    "**scale-location plot**\n",
    "shows the square root of the standardized residuals versus the fitted values, shows whether the size of the residuals get bigger or smaller, a more straight line shows not a huge change and a line that goes up and down all over the place means it's a poor fit\n",
    "    # first extract the normalized residuals from the model\n",
    "    model_norm_residuals_koi = mdl_koi.get_influence().resid_studentized_internal\n",
    "    # take the absolute values and take the square root of these norm resids to standardize them\n",
    "    model_norm_residuals_abs_sqrt_koi = np.sqrt(np.abs(model_norm_residuals_bream))\n",
    "    sns.regplot(x=mdl_koi.fittedvalues, y=model_norms_residuals_abs_sqrt_koi, ci=None, lowess=True)\n",
    "    plt.xlabel(\"Fitted Values\")\n",
    "    plt.ylabel(\"sqrt of abs val of stdized residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "Is your model overly affected by some unusual data points?\n",
    "an outlier is an unusual data point\n",
    "-an outlier can be an explanatory variable that is extreme (an extremely long/short koi)\n",
    "-an outlier could also be a point that's far from the model predictions (a koi with 0 mass)\n",
    "\n",
    "**Leverage**\n",
    "measure of how extreme the explanatory variable values are, highly leveraged points are the ones with explanatory variables that are furthest away from the others\n",
    "\n",
    "**Influence**\n",
    "measures how much the model would change if you left the observation out of the dataset when modeling, \"leave one out\" metric, influence is based on the size of the residuals and the leverage, the points far from the trendline \n",
    "\n",
    "**Cook's Distance**\n",
    "the most common measure of influence, you can find the most influential koi by arranging the rows by descending Cook's distance values\n",
    "\n",
    "use .get_influence() and .summary_frame() to get these metrics, the values of leverage are stored in the hat_diag column\n",
    "    mdl_koi = ols(\"mass ~ length\", data=koi).fit()\n",
    "    summary_roach = mdl_roach.get_influence().summary_frame()\n",
    "    koi[\"leverage\"] = summary_koi[\"hat_diag\"]\n",
    "    print(koi.sort_values(\"cooks_dist\", ascending=False).head())\n",
    "    \n",
    "you can remove the most influential koi\n",
    "    koi_not_short = koi[koi[\"length\"] != 12.9]\n",
    "    \n",
    "    sns.regplot(x=\"length\", \n",
    "                y=\"mass\",\n",
    "                data=koi,\n",
    "                ci=None,\n",
    "                line_kws={\"color\": \"green\"})\n",
    "                \n",
    "    sns.regplot(x=\"length\", \n",
    "                y=\"mass\",\n",
    "                data=koi_not_short,\n",
    "                ci=None,\n",
    "                line_kws={\"color\": \"red\"})\n",
    "                \n",
    "Code example:\n",
    "# Create summary_info\n",
    "summary_info = mdl_price_vs_dist.get_influence().summary_frame()\n",
    "\n",
    "# Add the hat_diag column to taiwan_real_estate, name it leverage\n",
    "taiwan_real_estate[\"leverage\"] = summary_info[\"hat_diag\"]\n",
    "\n",
    "# Add the cooks_d column to taiwan_real_estate, name it cooks_dist\n",
    "taiwan_real_estate[\"cooks_dist\"] = summary_info[\"cooks_d\"]\n",
    "\n",
    "# Sort taiwan_real_estate by cooks_dist in descending order and print the head.\n",
    "print(taiwan_real_estate.sort_values(\"cooks_dist\", ascending=False).head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
