{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5838b292",
   "metadata": {},
   "source": [
    "#### Intro to Modeling Data\n",
    "\n",
    "before building models, use exploratory data analysis like visualization and descriptive statistic to characterize the data to be modeled \n",
    "next, build the models and use them to make predictions\n",
    "quantify the confidence you have in those predictions\n",
    "this chapter will also show how linear regression relates to inferential statistics by introductiong model parameter estimation\n",
    "\n",
    "example applications of linear models\n",
    "linear models can be used to interpolate (a model prediction for times inbetween the times that wes actually measured) or extrapolate (a model prediction for a distance for a time outside the range of measured times)\n",
    "modeling can help you compare two data sets by building models for each and then comparing the models, for example figuring out fuel efficiency for two cars on the same roadtrip given gass consumption and refueling opportunities every 50 miles\n",
    "visualization methods are a great first step to seeing trends that may be harder to find or interpret had you just jumped straight to quantitative methods\n",
    "descriptive statistics will help you prepare a more quantitative basis for building a model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of a model as a python expression\n",
    "miles = 50 * hours\n",
    "\n",
    "# model predicts distance is 300 miles at 6 hours\n",
    "time = 6\n",
    "distance = 50 * time\n",
    "# this model predicts that you would travel 300 miles in 6 hours, 1500 miles in 30 hours, and so on....\n",
    "\n",
    "# models can also be expressed as functions\n",
    "def model(time):\n",
    "    return 50 * time\n",
    "\n",
    "predicted_distance = model(time=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd628a1",
   "metadata": {},
   "source": [
    "#### Visualizing Linear Relationships\n",
    "\n",
    "before building models it's useful to explore your data\n",
    "visualization is an important part of exploring data because it can detect qualities of the data that summary statistics might miss\n",
    "visualization is also great for communicating your data and modeling results to others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick plot, the data is stored as numpy arrays x and y and we want to plot it \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pass the data into the fuction plt.plot(), the string sets the plot style (r for red, - for solid line, o for round data point marker)\n",
    "plt.plot(x, y, \"r-o\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfda62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to use matplotlib, this is more object oriented, it's more customizable and easier to use for complex plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# construct two new objects, the figure object and the axis object\n",
    "# this is a method because it's part of an object or a class, if it's not then you can call it a function \n",
    "fig, axis = plt.subplots()\n",
    "\n",
    "# for ease of reuse, create a dictionary to store some of the style options\n",
    "options = dict(marker='o', color='blue')\n",
    "# could also add stuff like label=\"time\", marker=None\n",
    "\n",
    "# call the axis object method on the axis object\n",
    "# this uses ** unpacking to transform the dictionary key-value pairs into keyword arguments \n",
    "line = axis.plot(x, y **options)\n",
    "\n",
    "# add text labels to the axis object\n",
    "# this will set any unused output to the _\n",
    "_ = axis.set_ylabel(\"Times\")\n",
    "_ = axis.set_xlabel('Distances')\n",
    "\n",
    "# add grid lines and a legend\n",
    "axis.grid(True)\n",
    "axis.legend(loc=\"best\")\n",
    "\n",
    "# display the figure\n",
    "plt.show\n",
    "\n",
    "# once the data is plotted, you might see a linear relationship \n",
    "# how can you connect the plot to the ranges of values?\n",
    "\n",
    "# use two points\n",
    "# start with the point (x1, y1) at (0, 0)\n",
    "# move up some spaces (x2, y2) at (2, 3)\n",
    "\n",
    "# change in x and y\n",
    "# dy = (y2 - y1) = 3 - 0\n",
    "# dx = (x2 - x1) = 2 - 0\n",
    "\n",
    "# slope, rise over run, the ratio of increase in y, divided by the inclease in x\n",
    "# slope = dy/dx = 3/2\n",
    "\n",
    "# intercept, the y-intercept of the line is the y value where x=0\n",
    "# x=0:y1=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e2dcf",
   "metadata": {},
   "source": [
    "#### Quantifying Linear Relationships\n",
    "\n",
    "so far we've used data visualization to explore the relationship between two variables \n",
    "now we'll look at methods from descriptive statistics including correlation, which is a way of quatifying linear trends in the data, the correlation value is a quantitative measure of how strong of a linear relationship there is between the two variables in your data \n",
    "\n",
    "single variable statistics\n",
    "** mean, a measure of central tendency, describes the center of the data, mean = sum(x)/len(x)\n",
    "** deviation, a measure of spread, subtract the mean from every data point and the results are the deviations, dx = x - np.mean(x), if these are averaged the tend to cancel out to 0 since some will be positive and others will be negative\n",
    "** variance, the result of squaring the deviations and averaging, , to avoid the issue with deviation, we square them first and then average, variance = np.mean(dx*dx), variance measures how a single variable varies\n",
    "** standard deviation, square root of the variance, describes the spread of the data, the variance won't be the same units as the data anymore so take the square root, stdev = np.sqrt(variance) \n",
    "\n",
    "** covariance is a measure of whether two variables change (vary) together\n",
    "\n",
    "correlation always ranges from -1 to 1\n",
    "correlation has magnitude of 1 to 0, and a direction - (one goes up the other goes down) or + (one goes up and the other goes up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8db00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance measures how two variables vary together, compute the deviation arrays (dx and dy) from each of the two arrays x and y\n",
    "dx = x - np.mean(x)\n",
    "dy = y -np.mean(y)\n",
    "\n",
    "# get the product of each pair of deviations\n",
    "deviation_products = dx * dy\n",
    "\n",
    "# average all those products, covariance as the mean\n",
    "covariance = np.mean(dx * dy)\n",
    "# for each deviation product, if both x and y are varying in the same direction the result will be positive, \n",
    "# if they vary in opposite directions the product will be negative, therefore the average of those products will be larger if \n",
    "# both variables change in the same direction more often than not\n",
    "\n",
    "# as with variance, covariance can be difficult to interpret and compare\n",
    "# if we divide each deviation by the variables standard deviation the result is the covariance of the normalized deviations\n",
    "# aka the correlation\n",
    "\n",
    "# divide deviations by the standard deviation \n",
    "zx = dx/np.std(x)\n",
    "zy = dy/np.std(y)\n",
    "\n",
    "# correlation, mean of the normalized deviations\n",
    "correlation = np.mean(zx * zy)\n",
    "\n",
    "# why do we normalize?\n",
    "# if you're comparing two variables you'll run into trouble because they each have a different center spread so covariance \n",
    "# is harder to interpret and harder to compare to other data sets \n",
    "# after normalization, both variables will have a mean of 0 and a standard deviation of 1\n",
    "# if you imagine these are those deviations, no one variable will be weighted more heavily in the product anymore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc03827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example exercise \n",
    "#  in this exercise you will compare the 3 data sets by computing correlation, and determining which data set has the most strongly correlated variables x and y\n",
    "# Complete the function that will compute correlation.\n",
    "def correlation(x,y):\n",
    "    x_dev = x - np.mean(x)\n",
    "    y_dev = y - np.mean(y)\n",
    "    x_norm = x_dev / np.std(x)\n",
    "    y_norm = y_dev / np.std(y)\n",
    "    return np.mean(x_norm * y_norm)\n",
    "\n",
    "# Compute and store the correlation for each data set in the list.\n",
    "for name, data in data_sets.items():\n",
    "    data['correlation'] = correlation(data['x'], data['y'])\n",
    "    print('data set {} has correlation {:.2f}'.format(name, data['correlation']))\n",
    "\n",
    "# Assign the data set with the best correlation.\n",
    "best_data = data_sets['A']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
